# Image-Text-Retrieval-ann
This project explores cross-modal image–text retrieval using Artificial Neural Networks (ANNs). The goal is to learn a shared embedding space where semantically related images and text descriptions are aligned for effective retrieval.
## Problem Statement 
Image–text retrieval aims to retrieve relevant images given a text query, or relevant text given an image. Traditional approaches struggle with complex semantic relationships and noisy alignments. This project addresses these challenges using neural embedding learning and similarity-based retrieval.
## Methodology
- Image encoder to extract visual features
- Text encoder to extract semantic representations
- Projection into a shared embedding space
- Similarity computation using cosine similarity
- Training using contrastive loss
## Dataset
Flicker8K
##Tech Stack
- Python
- PyTorch
- Neural Networks
- Contrastive Learning
